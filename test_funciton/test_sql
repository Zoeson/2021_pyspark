
sql_item = 'select count(distinct(uid)) from rank.rank_user_profile_snapshot where concat(pday,phour)
            between "2021052101" and "2021052201" and uid is not null and dump_time is not null and recom_time is not null'
sql_user = 'select count(distinct(recom_id)) from rank.rank_news_profile_snapshot where concat(pday,phour)
        between "2021052101" and "2021052201" and recom_id is not null and dump_time is not null and recom_time is not null'



========================
import os
import sys
import datetime
import time
import re
import findspark
findspark.init()
from pyspark.sql import SparkSession


def init_spark():
    spark = SparkSession \
        .builder \
        .appName('name') \
        .enableHiveSupport() \
        .config("spark.driver.host", "localhost") \
        .getOrCreate()
    return spark


sc = init_spark()
sql_str = 'select uid, id, ctime from recom.load_expose_click where concat(pdate,phour) between "2021052101" and "2021052201" and uid is not null and id is not null and ctime is not null and sch not in ("relateDocOrig", "relateVideoOrig")'
rdd_data = sc.sql(sql_str).rdd.map(lambda line: '\t'.join([line.uid, line.id, line.ctime]))
rdd_item = rdd_data.groupByKey().mapValues(len)
rdd_filter = rdd_item.filter(lambda x:x[1] >3)
rdd_filter.count()
